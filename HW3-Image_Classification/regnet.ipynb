{"cells":[{"cell_type":"markdown","metadata":{},"source":["## HW3 Image Classification\n","#### Solve image classification with convolutional neural networks(CNN).\n","#### If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Reference\n","#### k-fold:https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-k-fold-cross-validation-with-keras.md"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:41:55.293458Z","iopub.status.busy":"2023-03-06T12:41:55.292615Z","iopub.status.idle":"2023-03-06T12:41:56.414165Z","shell.execute_reply":"2023-03-06T12:41:56.412686Z","shell.execute_reply.started":"2023-03-06T12:41:55.293416Z"},"trusted":true},"outputs":[],"source":["# check GPU type.\n","!nvidia-smi\n","'''\n","!unzip ml2023spring-hw3.\n","'''"]},{"cell_type":"markdown","metadata":{},"source":["### Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:01.638935Z","iopub.status.busy":"2023-03-06T12:42:01.637686Z","iopub.status.idle":"2023-03-06T12:42:01.644205Z","shell.execute_reply":"2023-03-06T12:42:01.642821Z","shell.execute_reply.started":"2023-03-06T12:42:01.638884Z"},"trusted":true},"outputs":[],"source":["_exp_name = \"sample\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:03.994470Z","iopub.status.busy":"2023-03-06T12:42:03.993501Z","iopub.status.idle":"2023-03-06T12:42:06.602986Z","shell.execute_reply":"2023-03-06T12:42:06.601849Z","shell.execute_reply.started":"2023-03-06T12:42:03.994417Z"},"trusted":true},"outputs":[],"source":["# Import necessary packages.\n","import numpy as np\n","import pandas as pd\n","import torch\n","import os\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","from PIL import Image\n","# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n","from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n","from torchvision.datasets import DatasetFolder, VisionDataset\n","# This is for the progress bar.\n","from tqdm.auto import tqdm\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:08.671999Z","iopub.status.busy":"2023-03-06T12:42:08.671281Z","iopub.status.idle":"2023-03-06T12:42:08.735685Z","shell.execute_reply":"2023-03-06T12:42:08.734697Z","shell.execute_reply.started":"2023-03-06T12:42:08.671963Z"},"trusted":true},"outputs":[],"source":["myseed = 6666  # set a random seed for reproducibility\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(myseed)\n","torch.manual_seed(myseed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(myseed)"]},{"cell_type":"markdown","metadata":{},"source":["### Transforms"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:10.865746Z","iopub.status.busy":"2023-03-06T12:42:10.864761Z","iopub.status.idle":"2023-03-06T12:42:10.871901Z","shell.execute_reply":"2023-03-06T12:42:10.870886Z","shell.execute_reply.started":"2023-03-06T12:42:10.865706Z"},"trusted":true},"outputs":[],"source":["# Normally, We don't need augmentations in testing and validation.\n","# All we need here is to resize the PIL image and transform it into Tensor.\n","brightness = (1, 10)\n","contrast = (1, 10)\n","saturation = (1, 10)\n","hue = (0.2, 0.4)\n","\n","test_tfm = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Resize((224, 224)),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    \n","    \n","])\n","\n","\n","# However, it is also possible to use augmentation in the testing phase.\n","# You may use train_tfm to produce a variety of images and then test using ensemble methods\n","train_tfm = transforms.Compose([\n","    # Resize the image into a fixed shape (height = width = 128)\n","    transforms.Resize((256, 256)),\n","    # You may add some transforms here.\n","    \n","    # ToTensor() should be the last one of the transforms.\n","    transforms.ToTensor(),\n","    \n","    transforms.RandomRotation(degrees=45),\n","    \n","    transforms.CenterCrop(224),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","    transforms.RandomGrayscale(p=0.2), \n","    transforms.RandomHorizontalFlip(p=0.5),\n","    #transforms.ColorJitter(contrast=0.5)\n","])\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:13.259609Z","iopub.status.busy":"2023-03-06T12:42:13.258557Z","iopub.status.idle":"2023-03-06T12:42:13.268650Z","shell.execute_reply":"2023-03-06T12:42:13.267304Z","shell.execute_reply.started":"2023-03-06T12:42:13.259548Z"},"trusted":true},"outputs":[],"source":["class FoodDataset(Dataset):\n","\n","    def __init__(self,path,tfm=test_tfm,files = None):\n","        super(FoodDataset).__init__()\n","        self.path = path\n","        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n","        \n","        if files != None:\n","            self.files = files\n","        self.transform = tfm\n","  \n","    def __len__(self):\n","        return len(self.files)\n","  \n","    def __getitem__(self,idx):\n","        fname = self.files[idx]\n","        im = Image.open(fname)\n","        im = self.transform(im)\n","        \n","        try:\n","            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n","        except:\n","            label = -1 # test has no label\n","            \n","        return im,label"]},{"cell_type":"markdown","metadata":{},"source":["### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:16.971206Z","iopub.status.busy":"2023-03-06T12:42:16.970826Z","iopub.status.idle":"2023-03-06T12:42:16.985456Z","shell.execute_reply":"2023-03-06T12:42:16.981608Z","shell.execute_reply.started":"2023-03-06T12:42:16.971173Z"},"trusted":true},"outputs":[],"source":["from torchvision.models import resnet50, vgg16,alexnet,densenet201,shufflenet_v2_x2_0,regnet_x_16gf\n","\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super(Classifier, self).__init__()\n","        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n","        # input 維度 [3, 128, 128]\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n","\n","            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n","\n","            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n","\n","            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n","            \n","            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(512*4*4, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 11)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear(512*4*4, 1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 11)\n","        )\n","        #self.weights=VGG16_Weights.DEFAULT\n","        self.resNet=regnet_x_16gf()\n","        self.fc2=nn.Sequential(nn.Linear(1000, 11))\n","\n","\n","    def forward(self, x):\n","        x = self.resNet(x)\n","        out=x\n","        #out = self.fc2(x)\n","        return out"]},{"cell_type":"markdown","metadata":{},"source":["### Configurations"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:48.157271Z","iopub.status.busy":"2023-03-06T12:42:48.156224Z","iopub.status.idle":"2023-03-06T12:42:48.301646Z","shell.execute_reply":"2023-03-06T12:42:48.300565Z","shell.execute_reply.started":"2023-03-06T12:42:48.157219Z"},"trusted":true},"outputs":[],"source":["# \"cuda\" only when GPUs are available.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# Initialize a model, and put it on the device specified.\n","model = Classifier().to(device)\n","\n","# The number of batch size.\n","batch_size = 32\n","\n","# The number of training epochs.\n","n_epochs = 500\n","\n","# If no improvement in 'patience' epochs, early stop.\n","patience = 50\n","\n","# For the classification task, we use cross-entropy as the measurement of performance.\n","criterion = nn.CrossEntropyLoss()\n","\n","# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Example of target with class indices\n","loss = nn.CrossEntropyLoss()\n","input = torch.randn(3, 5, requires_grad=True)\n","target = torch.empty(3, dtype=torch.long).random_(5)\n","output = loss(input, target)\n","output.backward()\n","# Example of target with class probabilities\n","input = torch.randn(3, 5, requires_grad=True)\n","target = torch.randn(3, 5).softmax(dim=1)\n","output = loss(input, target)\n","output.backward()\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:50.556350Z","iopub.status.busy":"2023-03-06T12:42:50.555896Z","iopub.status.idle":"2023-03-06T12:42:52.184902Z","shell.execute_reply":"2023-03-06T12:42:52.183686Z","shell.execute_reply.started":"2023-03-06T12:42:50.556303Z"},"trusted":true},"outputs":[],"source":["# Construct train and valid datasets.\n","# The argument \"loader\" tells how torchvision reads the data.\n","\n","train_set = FoodDataset(\"./train\", tfm=train_tfm)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","valid_set = FoodDataset(\"./valid\", tfm=test_tfm)\n","valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataset = torch.utils.data.ConcatDataset([train_set, valid_set])"]},{"cell_type":"markdown","metadata":{},"source":["### Start Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Buitl\n","\n","from datetime import datetime\n","from sklearn.model_selection import KFold\n","import pandas as pd\n","import json\n","currentDateAndTime = datetime.now()\n","\n","os.makedirs('./model', exist_ok=True)\n","os.makedirs(\"result\", exist_ok=True)\n","\n","\n","sourceFile = open('result/result_'+str(currentDateAndTime)+'.txt', 'w')\n","\n","\n","print(model,file = sourceFile)\n","\n","sourceFile.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:42:58.525574Z","iopub.status.busy":"2023-03-06T12:42:58.525093Z","iopub.status.idle":"2023-03-06T12:47:26.360560Z","shell.execute_reply":"2023-03-06T12:47:26.358987Z","shell.execute_reply.started":"2023-03-06T12:42:58.525522Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n","from sklearn.model_selection import KFold\n","\n","splits = KFold(n_splits=5, shuffle=True)\n","for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n","#for fold in range(5):\n","\n","    print(\"fold:\",fold)\n","    _exp_name = \"./model/\"+\"kfold_\"+str(fold)\n","    model = Classifier().to(device)\n","    \n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)\n","    stale = 0\n","    best_acc = 0\n","    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=8)\n","    train_sampler = SubsetRandomSampler(train_idx)\n","    test_sampler = SubsetRandomSampler(val_idx)\n","    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n","    valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n","\n","    for epoch in range(n_epochs):\n","\n","        # ---------- Training ----------\n","        # Make sure the model is in train mode before training.\n","        model.train()\n","\n","        # These are used to record information in training.\n","        train_loss = []\n","        train_accs = []\n","\n","        for batch in tqdm(train_loader):\n","\n","            # A batch consists of image data and corresponding labels.\n","            imgs, labels = batch\n","            #imgs = imgs.half()\n","            #print(imgs.shape,labels.shape)\n","\n","            # Forward the data. (Make sure data and model are on the same device.)\n","            logits = model(imgs.to(device))\n","\n","            # Calculate the cross-entropy loss.\n","            # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n","            loss = criterion(logits, labels.to(device))\n","\n","            # Gradients stored in the parameters in the previous step should be cleared out first.\n","            optimizer.zero_grad()\n","\n","            # Compute the gradients for parameters.\n","            loss.backward()\n","\n","            # Clip the gradient norms for stable training.\n","            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n","\n","            # Update the parameters with computed gradients.\n","            optimizer.step()\n","\n","            # Compute the accuracy for current batch.\n","            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","            # Record the loss and accuracy.\n","            train_loss.append(loss.item())\n","            train_accs.append(acc)\n","            \n","        train_loss = sum(train_loss) / len(train_loss)\n","        train_acc = sum(train_accs) / len(train_accs)\n","\n","        # Print the information.\n","        print(f\"[fold {fold}| Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n","        \n","        \n","        sourceFile = open('result/result_'+str(currentDateAndTime)+'.txt', 'a+')\n","        print(f\"[fold {fold} Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\",file=sourceFile)\n","        sourceFile.close()\n","        scheduler.step()\n","        # ---------- Validation ----------\n","        # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n","        model.eval()\n","\n","        # These are used to record information in validation.\n","        valid_loss = []\n","        valid_accs = []\n","        \n","        # Iterate the validation set by batches.\n","        for batch in tqdm(valid_loader):\n","\n","            # A batch consists of image data and corresponding labels.\n","            imgs, labels = batch\n","            #imgs = imgs.half()\n","\n","            # We don't need gradient in validation.\n","            # Using torch.no_grad() accelerates the forward process.\n","            with torch.no_grad():\n","                logits = model(imgs.to(device))\n","\n","            # We can still compute the loss (but not the gradient).\n","\n","\n","            loss = criterion(logits, labels.to(device))\n","\n","            # Compute the accuracy for current batch.\n","            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n","\n","            # Record the loss and accuracy.\n","            valid_loss.append(loss.item())\n","            valid_accs.append(acc)\n","            #break\n","\n","        # The average loss and accuracy for entire validation set is the average of the recorded values.\n","        valid_loss = sum(valid_loss) / len(valid_loss)\n","        valid_acc = sum(valid_accs) / len(valid_accs)\n","\n","        # Print the information.\n","        sourceFile = open('result/result_'+str(currentDateAndTime)+'.txt', 'a+')\n","        #print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\",file=sourceFile)\n","        \n","        print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","\n","\n","        # update logs\n","        if valid_acc > best_acc:\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\",file=sourceFile)\n","            with open(f\"./{_exp_name}_log.txt\",\"a+\"):\n","                print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n","        else:\n","            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\",file=sourceFile)\n","            with open(f\"./{_exp_name}_log.txt\",\"a+\"):\n","                print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n","        sourceFile.close()\n","\n","        # save models\n","        if valid_acc > best_acc:\n","            print(f\"Best model found at epoch {epoch}, saving model\")\n","            torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n","            best_acc = valid_acc\n","            stale = 0\n","        else:\n","            stale += 1\n","            if stale > patience:\n","                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n","                break"]},{"cell_type":"markdown","metadata":{},"source":["### Dataloader for test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:47:31.638946Z","iopub.status.busy":"2023-03-06T12:47:31.637882Z","iopub.status.idle":"2023-03-06T12:47:32.085514Z","shell.execute_reply":"2023-03-06T12:47:32.084453Z","shell.execute_reply.started":"2023-03-06T12:47:31.638899Z"},"trusted":true},"outputs":[],"source":["# Construct test datasets.\n","# The argument \"loader\" tells how torchvision reads the data.\n","test_set = FoodDataset(\"./test\", tfm=test_tfm)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Testing and generate prediction CSV"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","def ensemble(models,features):\n","    \n","    preds=torch.zeros(len(models),features.size(0),dtype=torch.int32)\n","    #preds[0]=df\n","    for i in range(len(models)):\n","        #print(i)\n","        model=models[i]\n","        model.eval()\n","        with torch.no_grad():\n","            outputs = model(features)\n","            _, val_pred = torch.max(outputs, 1) \n","            preds[i]=val_pred\n","    out=torch.zeros(features.size(0))\n","    for i in range(features.size(0)):\n","        pred=preds[:,i]\n","        weight=pred[0]\n","        pred=torch.bincount(pred)\n","        #pred[weight]+=1\n","       \n","        sorted, indices = torch.sort(pred)\n","        \n","        '''\n","        if sorted.size(0)!=1 and sorted[0]==sorted[1]:\n","            out[i]=int(preds[0,i])\n","        else:\n","        '''\n","        out[i]=int(torch.argmax(pred))\n","        \n","    #print('out:',out.size())\n","    return out\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:48:40.395319Z","iopub.status.busy":"2023-03-06T12:48:40.394641Z","iopub.status.idle":"2023-03-06T12:49:24.735001Z","shell.execute_reply":"2023-03-06T12:49:24.733969Z","shell.execute_reply.started":"2023-03-06T12:48:40.395279Z"},"trusted":true},"outputs":[],"source":["models_path=['./model/kfold_0_best.ckpt',\n","             './model/kfold_1_best.ckpt',\n","             './model/kfold_2_best.ckpt',\n","             './model/kfold_3_best.ckpt',\n","             './model/kfold_4_best.ckpt']\n","\n","models=[]\n","for i in range(len(models_path)):\n","    model_best = Classifier().to(device)\n","    model_best.load_state_dict(torch.load(models_path[i]))\n","    \n","    model_best.eval()\n","    models.append(model_best)\n","\n","prediction = []\n","with torch.no_grad():\n","    for data,_ in tqdm(test_loader):\n","        test_label = ensemble(models,data.to(device))\n","        #test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n","        prediction += test_label.squeeze().tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-06T12:49:30.701796Z","iopub.status.busy":"2023-03-06T12:49:30.700780Z","iopub.status.idle":"2023-03-06T12:49:30.718186Z","shell.execute_reply":"2023-03-06T12:49:30.716859Z","shell.execute_reply.started":"2023-03-06T12:49:30.701756Z"},"trusted":true},"outputs":[],"source":["#create test csv\n","def pad4(i):\n","    return \"0\"*(4-len(str(i)))+str(i)\n","df = pd.DataFrame()\n","df[\"Id\"] = [pad4(i) for i in range(len(test_set))]\n","df[\"Category\"] = list(map(int, prediction))\n","df.to_csv(\"submission.csv\",index = False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.15"},"vscode":{"interpreter":{"hash":"2f10633d0c2d43d8856f9bd12e5a0229ed2dd9aaabeb3fbc88420d061c41e2c4"}}},"nbformat":4,"nbformat_minor":4}

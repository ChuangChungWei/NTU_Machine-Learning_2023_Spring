{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "H9m2AbpHC9vS"
      },
      "source": [
        "# **Homework 10 - Adversarial Attack**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k0G8g5KuDBzU"
      },
      "source": [
        "## Enviroment & Download\n",
        "\n",
        "We make use of [pytorchcv](https://pypi.org/project/pytorchcv/) to obtain CIFAR-10 pretrained model, so we need to set up the enviroment first. We also need to download the data (200 images) which we want to attack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "yMK1RhUQCz1e",
        "outputId": "93fbc34c-794b-4848-aea4-2645d91f203d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\n# set up environment\\n!pip install pytorchcv\\n!pip install imgaug\\n\\n# download\\n#!gdown --id 1t2UFQXr1cr5qLMBK2oN2rY1NDypi9Nyw --output data.zip\\n\\n# if the above link isn't available, try this one\\n\\n!wget https://www.dropbox.com/s/lbpypqamqjpt2qz/data.zip\\n\\n# unzip\\n!unzip ./data.zip\\n\""
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "# set up environment\n",
        "!pip install pytorchcv\n",
        "!pip install imgaug\n",
        "\n",
        "# download\n",
        "#!gdown --id 1t2UFQXr1cr5qLMBK2oN2rY1NDypi9Nyw --output data.zip\n",
        "\n",
        "# if the above link isn't available, try this one\n",
        "\n",
        "!wget https://www.dropbox.com/s/lbpypqamqjpt2qz/data.zip\n",
        "\n",
        "# unzip\n",
        "!unzip ./data.zip\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-a6naDouEWUZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove './data.zip': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!rm ./data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SaEEx0Y3DMdu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "batch_size = 8\n",
        "\n",
        "def same_seeds(seed):\n",
        "\t  torch.manual_seed(seed)\n",
        "\t  if torch.cuda.is_available():\n",
        "\t\t    torch.cuda.manual_seed(seed)\n",
        "\t\t    torch.cuda.manual_seed_all(seed)\n",
        "\t  np.random.seed(seed)\n",
        "\t  random.seed(seed)\n",
        "\t  torch.backends.cudnn.benchmark = False\n",
        "\t  torch.backends.cudnn.deterministic = True\n",
        "same_seeds(0) "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8mIr7c0DPsh"
      },
      "source": [
        "## Global Settings \n",
        "#### **[NOTE]**: Don't change the settings here, or your generated image might not meet the constraint.\n",
        "* $\\epsilon$ is fixed to be 8. But on **Data section**, we will first apply transforms on raw pixel value (0-255 scale) **by ToTensor (to 0-1 scale)** and then **Normalize (subtract mean divide std)**. $\\epsilon$ should be set to $\\frac{8}{255 * std}$ during attack.\n",
        "\n",
        "* Explaination (optional)\n",
        "    * Denote the first pixel of original image as $p$, and the first pixel of adversarial image as $a$.\n",
        "    * The $\\epsilon$ constraints tell us $\\left| p-a \\right| <= 8$.\n",
        "    * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
        "    * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
        "    * After applying ToTensor() and Normalize() on $p$ and $a$, the constraint becomes $\\left| N(T(p))-N(T(a)) \\right| = \\left| \\frac{\\frac{p}{255}-mean}{std}-\\frac{\\frac{a}{255}-mean}{std} \\right| = \\frac{1}{255 * std} \\left| p-a \\right| <= \\frac{8}{255 * std}.$\n",
        "    * So, we should set $\\epsilon$ to be $\\frac{8}{255 * std}$ after ToTensor() and Normalize()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IBdYgS2DDNL5"
      },
      "outputs": [],
      "source": [
        "# the mean and std are the calculated statistics from cifar_10 dataset\n",
        "cifar_10_mean = (0.491, 0.482, 0.447) # mean for the three channels of cifar_10 images\n",
        "cifar_10_std = (0.202, 0.199, 0.201) # std for the three channels of cifar_10 images\n",
        "\n",
        "# convert mean and std to 3-dimensional tensors for future operations\n",
        "mean = torch.tensor(cifar_10_mean).to(device).view(3, 1, 1)\n",
        "std = torch.tensor(cifar_10_std).to(device).view(3, 1, 1)\n",
        "\n",
        "epsilon = 8/255/std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AjNkQLoaDWba"
      },
      "outputs": [],
      "source": [
        "root = './data' # directory for storing benign images\n",
        "# benign images: images which do not contain adversarial perturbations\n",
        "# adversarial images: images which include adversarial perturbations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sNf-LoODDZXB"
      },
      "source": [
        "## Data\n",
        "\n",
        "Construct dataset and dataloader from root directory. Note that we store the filename of each image for future usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV7rbnD5DarR",
        "outputId": "fd67b848-457f-46a6-80a3-197e1a14abb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of images = 200\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(cifar_10_mean, cifar_10_std)\n",
        "])\n",
        "\n",
        "class AdvDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform):\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.names = []\n",
        "        '''\n",
        "        data_dir\n",
        "        ├── class_dir\n",
        "        │   ├── class1.png\n",
        "        │   ├── ...\n",
        "        │   ├── class20.png\n",
        "        '''\n",
        "        for i, class_dir in enumerate(sorted(glob.glob(f'{data_dir}/*'))):\n",
        "            images = sorted(glob.glob(f'{class_dir}/*'))\n",
        "            self.images += images\n",
        "            self.labels += ([i] * len(images))\n",
        "            self.names += [os.path.relpath(imgs, data_dir) for imgs in images]\n",
        "        self.transform = transform\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.transform(Image.open(self.images[idx]))\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "    def __getname__(self):\n",
        "        return self.names\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "adv_set = AdvDataset(root, transform=transform)\n",
        "adv_names = adv_set.__getname__()\n",
        "adv_loader = DataLoader(adv_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f'number of images = {adv_set.__len__()}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "C9D7eakEDflF"
      },
      "source": [
        "## Utils -- Benign Images Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "byE4VH3uDduA"
      },
      "outputs": [],
      "source": [
        "# to evaluate the performance of model on benign images\n",
        "def epoch_benign(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    train_acc, train_loss = 0.0, 0.0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        yp = model(x)\n",
        "        loss = loss_fn(yp, y)\n",
        "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
        "        train_loss += loss.item() * x.shape[0]\n",
        "    return train_acc / len(loader.dataset), train_loss / len(loader.dataset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D3L_qtufDk4j"
      },
      "source": [
        "## Utils -- Attack Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "odTOhtrtDklT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "# perform fgsm attack\n",
        "epsilon = 8/255/std\n",
        "def fgsm(model, x, y, loss_fn, epsilon=epsilon):\n",
        "    #global epsilon\n",
        "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
        "    x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
        "    loss = loss_fn(model(x_adv), y) # calculate loss\n",
        "    loss.backward() # calculate gradient\n",
        "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
        "    grad = x_adv.grad.detach()\n",
        "    x_adv = x_adv + epsilon * grad.sign()\n",
        "    return x_adv\n",
        "\n",
        "# alpha and num_iter can be decided by yourself\n",
        "alpha = 0.8/255/std\n",
        "alpha = 2/255/std\n",
        "\n",
        "def DIM(x):\n",
        "  p=random.random()\n",
        "  ratio=random.randint(25,31)\n",
        "  #print(x.size())\n",
        "  resize=random.randint(25,31)\n",
        "  if p>=0.5:\n",
        "    r1=random.randint(1,32-resize)\n",
        "    l=32-r1\n",
        "    r1=random.randint(1,32-resize)\n",
        "    u=32-r1\n",
        "    r=32-resize-l\n",
        "    d=32-resize-u\n",
        "    padding=(l,u,r,d)\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(resize),\n",
        "      transforms.Pad(padding, fill=0,padding_mode=\"constant\"), \n",
        "    ])\n",
        "    x=transform(x)\n",
        "    #print(x.size())\n",
        "\n",
        "  \n",
        "  return x\n",
        "  \n",
        "def ifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20):\n",
        "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
        "    #x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
        "    g_t = loss_fn(model(x_adv), y) # calculate loss\n",
        "\n",
        "    min_adv,max_adv=torch.min(x_adv),torch.max(x_adv)\n",
        "    #loss.backward() # calculate gradient\n",
        "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
        "    #grad = x_adv.grad.detach()\n",
        "    #x_adv = x_adv + epsilon * grad.sign()\n",
        "\n",
        "    # initialze momentum tensor\n",
        "    momentum = torch.zeros_like(x).detach().to(device)\n",
        "    mu=0\n",
        "    ################ TODO: Strong baseline ####################\n",
        "    for i in range(num_iter):\n",
        "      #print(i)\n",
        "      # TODO: Refer to the algorithm of MI-FGSM\n",
        "      # Calculate the momentum and update\n",
        "      #x_adv=DIM(x_adv)\n",
        "      #print(type(x_adv))\n",
        "      x_adv.requires_grad = True\n",
        "      #min_adv,max_adv=torch.min(x_adv),torch.max(x_adv)\n",
        "      loss=loss_fn(model(x_adv), y)\n",
        "      \n",
        "      \n",
        "      #print(type(x_adv))\n",
        "      '''\n",
        "      g_t=mu*g_t.detach()+loss/abs(loss)\n",
        "      g_t.backward()\n",
        "      '''\n",
        "      \n",
        "      loss.backward()\n",
        "      grad = x_adv.grad.detach()\n",
        "      x_adv=x_adv+alpha*grad.sign()\n",
        "      x_adv=torch.clip(x_adv,x-epsilon,x+epsilon)\n",
        "      x_adv=x_adv.detach().clone()\n",
        "    return x_adv\n",
        "\n",
        "\n",
        "\n",
        "def mifgsm(model, x, y, loss_fn, epsilon=epsilon, alpha=alpha, num_iter=20, decay=0.3):\n",
        "\n",
        "    x_adv = x.detach().clone() # initialize x_adv as original benign image x\n",
        "    #x_adv.requires_grad = True # need to obtain gradient of x_adv, thus set required grad\n",
        "    g_t = loss_fn(model(x_adv), y) # calculate loss\n",
        "\n",
        "    min_adv,max_adv=torch.min(x_adv),torch.max(x_adv)\n",
        "    #loss.backward() # calculate gradient\n",
        "    # fgsm: use gradient ascent on x_adv to maximize loss\n",
        "    #grad = x_adv.grad.detach()\n",
        "    #x_adv = x_adv + epsilon * grad.sign()\n",
        "\n",
        "    # initialze momentum tensor\n",
        "    momentum = torch.zeros_like(x).detach().to(device)\n",
        "    mu=1\n",
        "    g_t=0\n",
        "    alpha=8/num_iter\n",
        "    #epsilon=4/255\n",
        "    ################ TODO: Strong baseline ####################\n",
        "    for i in range(num_iter):\n",
        "      #print(i)\n",
        "      # TODO: Refer to the algorithm of MI-FGSM\n",
        "      # Calculate the momentum and update\n",
        "      #x_adv=DIM(x_adv)\n",
        "      #print(type(x_adv))\n",
        "      x_adv.requires_grad = True\n",
        "      #min_adv,max_adv=torch.min(x_adv),torch.max(x_adv)\n",
        "      loss=loss_fn(model(x_adv), y)\n",
        "      \n",
        "      \n",
        "      #print(type(x_adv))\n",
        "      '''\n",
        "      g_t=mu*g_t.detach()+loss/abs(loss)\n",
        "      g_t.backward()\n",
        "      '''\n",
        "      \n",
        "      loss.backward()\n",
        "      grad = x_adv.grad.detach()\n",
        "      g_t=mu*g_t+grad/abs(grad)\n",
        "      #print(grad.sign())\n",
        "      #print(g_t.sign())\n",
        "      x_adv=x_adv+alpha*g_t.sign()\n",
        "      x_adv=torch.clip(x_adv,x-epsilon,x+epsilon)\n",
        "      x_adv=x_adv.detach().clone()\n",
        "    return x_adv"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0o9ww4s1DrEx"
      },
      "source": [
        "## Utils -- Attack\n",
        "* Recall\n",
        "  * ToTensor() can be seen as a function where $T(x) = x/255$.\n",
        "  * Normalize() can be seen as a function where $N(x) = (x-mean)/std$ where $mean$ and $std$ are constants.\n",
        "\n",
        "* Inverse function\n",
        "  * Inverse Normalize() can be seen as a function where $N^{-1}(x) = x*std+mean$ where $mean$ and $std$ are constants.\n",
        "  * Inverse ToTensor() can be seen as a function where $T^{-1}(x) = x*255$.\n",
        "\n",
        "* Special Noted\n",
        "  * ToTensor() will also convert the image from shape (height, width, channel) to shape (channel, height, width), so we also need to transpose the shape back to original shape.\n",
        "  * Since our dataloader samples a batch of data, what we need here is to transpose **(batch_size, channel, height, width)** back to **(batch_size, height, width, channel)** using np.transpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "rbtfv7rjDrvR"
      },
      "outputs": [],
      "source": [
        "# perform adversarial attack and generate adversarial examples\n",
        "def gen_adv_examples(model, loader, attack, loss_fn):\n",
        "    model.eval()\n",
        "    adv_names = []\n",
        "    train_acc, train_loss = 0.0, 0.0\n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        if i%5==0:\n",
        "          print(i,\"/\",len(loader))\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x_adv = attack(model, x, y, loss_fn) # obtain adversarial examples\n",
        "        yp = model(x_adv)\n",
        "        loss = loss_fn(yp, y)\n",
        "        train_acc += (yp.argmax(dim=1) == y).sum().item()\n",
        "        train_loss += loss.item() * x.shape[0]\n",
        "        # store adversarial examples\n",
        "        adv_ex = ((x_adv) * std + mean).clamp(0, 1) # to 0-1 scale\n",
        "        adv_ex = (adv_ex * 255).clamp(0, 255) # 0-255 scale\n",
        "        adv_ex = adv_ex.detach().cpu().data.numpy().round() # round to remove decimal part\n",
        "        adv_ex = adv_ex.transpose((0, 2, 3, 1)) # transpose (bs, C, H, W) back to (bs, H, W, C)\n",
        "        adv_examples = adv_ex if i == 0 else np.r_[adv_examples, adv_ex]\n",
        "    return adv_examples, train_acc / len(loader.dataset), train_loss / len(loader.dataset)\n",
        "\n",
        "# create directory which stores adversarial examples\n",
        "def create_dir(data_dir, adv_dir, adv_examples, adv_names):\n",
        "    if os.path.exists(adv_dir) is not True:\n",
        "        _ = shutil.copytree(data_dir, adv_dir)\n",
        "    for example, name in zip(adv_examples, adv_names):\n",
        "        im = Image.fromarray(example.astype(np.uint8)) # image pixel value should be unsigned int\n",
        "        im.save(os.path.join(adv_dir, name))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rbLBR4bjDu7h"
      },
      "source": [
        "## Model / Loss Function\n",
        "\n",
        "Model list is available [here](https://github.com/osmr/imgclsmob/blob/master/pytorch/pytorchcv/model_provider.py). Please select models which has _cifar10 suffix. Other kinds of models are prohibited, and it will be considered to be cheating if you use them. \n",
        "\n",
        "Note: Some of the models cannot be accessed/loaded. You can safely skip them since TA's model will not use those kinds of models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xCKMshb08I1I"
      },
      "outputs": [],
      "source": [
        "# This function is used to check whether you use models pretrained on cifar10 instead of other datasets\n",
        "def model_checker(model_name):\n",
        "  assert ('cifar10' in model_name) and ('cifar100' not in model_name), 'The model selected is not pretrained on cifar10!'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCJU4k__DwPT",
        "outputId": "be9c2d39-730b-4a01-c305-6f6ade56e7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign_acc = 0.95000, benign_loss = 0.22690\n"
          ]
        }
      ],
      "source": [
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "\n",
        "model_name = 'resnet110_cifar10'\n",
        "model_checker(model_name)\n",
        "\n",
        "model = ptcv_get_model(model_name, pretrained=True).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
        "print(f'benign_acc = {benign_acc:.5f}, benign_loss = {benign_loss:.5f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IWEW8IY8rmc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['preresnet20_cifar10', 'seresnet20_cifar10', 'diapreresnet20_cifar10', 'densenet40_k12_cifar10', 'ror3_56_cifar10', 'resnet56_cifar10', 'sepreresnet56_cifar10', 'diaresnet56_cifar10', 'nin_cifar10', 'preresnet164bn_cifar10', 'preresnet110_cifar10', 'sepreresnet110_cifar10', 'sepreresnet164bn_cifar10', 'diapreresnet110_cifar10', 'densenet40_k24_bc_cifar10', 'densenet190_k40_bc_cifar10', 'diaresnet164bn_cifar10', 'pyramidnet110_a48_cifar10', 'resnet272bn_cifar10', 'seresnet272bn_cifar10', 'densenet40_k36_bc_cifar10', 'pyramidnet110_a84_cifar10', 'preresnet542bn_cifar10', 'sepreresnet542bn_cifar10', 'rir_cifar10']\n",
            "25\n",
            "total memory: 8778.79\n",
            "average error: 4.4588\n"
          ]
        }
      ],
      "source": [
        "################ BOSS BASELINE ######################\n",
        "\n",
        "class ensembleNet(nn.Module):\n",
        "    def __init__(self, model_names):\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        self.models = nn.ModuleList([ptcv_get_model(name, pretrained=True) for name in model_names])\n",
        "        self.model_names=model_names\n",
        "    def forward(self, x):\n",
        "        #################### TODO: boss baseline ###################\n",
        "        ensemble_logits=torch.zeros(self.models[0](x).size()).to('cuda')\n",
        "        for i, m in enumerate(self.models):\n",
        "          #print(self.model_names[i])\n",
        "          ensemble_logits+=m(x)\n",
        "        ensemble_logits=ensemble_logits/len(self.models)\n",
        "        # TODO: sum up logits from multiple models  \n",
        "        return ensemble_logits\n",
        "model_names = [\n",
        "    'preresnet542bn_cifar10',\n",
        "    'pyramidnet272_a200_bn_cifar10',\n",
        "    'preresnet1001_cifar10',\n",
        "    'wrn16_10_cifar10',\n",
        "    'pyramidnet110_a84_cifar10',\n",
        "    'nin_cifar10',\n",
        "    'resnet110_cifar10',\n",
        "    'sepreresnet542bn_cifar10',\n",
        "    'sepreresnet272bn_cifar10',\n",
        "    'preresnet56_cifar10',\n",
        "    'resnext29_16x64d_cifar10',\n",
        "]\n",
        "model_names=['wrn16_10_cifar10', \n",
        "             'pyramidnet272_a200_bn_cifar10', \n",
        "             'preresnet1001_cifar10', \n",
        "             'wrn16_10_cifar10', \n",
        "             'pyramidnet110_a84_cifar10', \n",
        "             'nin_cifar10', \n",
        "             'resnet110_cifar10', \n",
        "             'preresnet56_cifar10', \n",
        "             'resnext29_16x64d_cifar10']\n",
        "model_names=['shakeshakeresnet26_2x32d_cifar10',\n",
        "             'preresnet272bn_cifar10',\n",
        "             'seresnet56_cifar10',\n",
        "             'sepreresnet56_cifar10',\n",
        "             'ror3_110_cifar10',\n",
        "             'preresnet110_cifar10',\n",
        "             'resnet164bn_cifar10',\n",
        "             'resnet110_cifar10',\n",
        "             'seresnet110_cifar10',\n",
        "             'seresnet164bn_cifar10',\n",
        "             'sepreresnet164bn_cifar10',\n",
        "             'diaresnet164bn_cifar10',\n",
        "             'ror3_164_cifar10',\n",
        "             \n",
        "             ]\n",
        "model_dict={'preresnet20_cifar10':[41.27,6.51],\n",
        "'resnet20_cifar10':[41.29,5.97],\n",
        "'seresnet20_cifar10':[41.34,6.01],\n",
        "'sepreresnet20_cifar10':[41.35,6.18],\n",
        "'diapreresnet20_cifar10':[41.52,6.42],\n",
        "'diaresnet20_cifar10':[41.54,6.22],\n",
        "'densenet40_k12_cifar10':[74.89,6.43],\n",
        "'shakeshakeresnet20_2x16d_cifar10':[81.78,5.15],\n",
        "'ror3_56_cifar10':[113.43,5.43],\n",
        "'preresnet56_cifar10':[127.03,4.49],\n",
        "'resnet56_cifar10':[127.06,4.52],\n",
        "'seresnet56_cifar10':[127.19,4.13],\n",
        "'sepreresnet56_cifar10':[127.2,4.51],\n",
        "'diapreresnet56_cifar10':[129.28,4.83],\n",
        "'diaresnet56_cifar10':[129.31,5.05],\n",
        "'densenet100_k12_bc_cifar10':[210.8,5.61],\n",
        "'nin_cifar10':[222.97,7.43],\n",
        "'ror3_110_cifar10':[242.07,4.35],\n",
        "'preresnet164bn_cifar10':[255.08,3.64],\n",
        "'resnet164bn_cifar10':[255.31,3.68],\n",
        "'preresnet110_cifar10':[255.68,3.86],\n",
        "'resnet110_cifar10':[255.7,3.69],\n",
        "'sepreresnet110_cifar10':[255.98,4.54],\n",
        "'seresnet110_cifar10':[255.98,3.63],\n",
        "'sepreresnet164bn_cifar10':[256.32,3.73],\n",
        "'seresnet164bn_cifar10':[256.55,3.39],\n",
        "'diapreresnet110_cifar10':[264.69,4.25],\n",
        "'diaresnet110_cifar10':[264.71,4.1],\n",
        "'densenet40_k24_bc_cifar10':[293.09,4.52],\n",
        "'xdensenet40_2_k24_bc_cifar10':[293.09,5.31],\n",
        "'densenet190_k40_bc_cifar10':[298.45,4.16],\n",
        "'diapreresnet164bn_cifar10':[343.37,3.56],\n",
        "'diaresnet164bn_cifar10':[343.6,3.5],\n",
        "'ror3_164_cifar10':[370.72,3.93],\n",
        "'pyramidnet110_a48_cifar10':[408.37,3.72],\n",
        "'preresnet272bn_cifar10':[420.38,3.25],\n",
        "'resnet272bn_cifar10':[420.61,3.33],\n",
        "'sepreresnet272bn_cifar10':[422.45,3.39],\n",
        "'seresnet272bn_cifar10':[422.68,3.39],\n",
        "'shakeshakeresnet26_2x32d_cifar10':[428.89,3.17],\n",
        "'densenet40_k36_bc_cifar10':[654.6,4.04],\n",
        "'xdensenet40_2_k36_bc_cifar10':[654.6,4.37],\n",
        "'pyramidnet110_a84_cifar10':[778.15,2.98],\n",
        "'resnext29_32x4d_cifar10':[780.55,3.15],\n",
        "'preresnet542bn_cifar10':[833.64,3.14],\n",
        "'resnet542bn_cifar10':[833.87,3.43],\n",
        "'sepreresnet542bn_cifar10':[837.78,3.08],\n",
        "'seresnet542bn_cifar10':[838.01,3.47],\n",
        "'rir_cifar10':[1281.08,3.28],\n",
        "'densenet100_k12_cifar10':[1353.55,3.66],\n",
        "'preresnet1001_cifar10':[1536.18,2.65],\n",
        "'resnet1001_cifar10':[1536.4,3.28],\n",
        "'wrn16_10_cifar10':[2414.04,2.93],\n",
        "'preresnet1202_cifar10':[2857.14,3.39],\n",
        "'resnet1202_cifar10':[2857.17,3.53],\n",
        "'wrn20_10_1bit_cifar10':[4019.14,3.26],\n",
        "'wrn20_10_32bit_cifar10':[4019.14,3.14],\n",
        "'pyramidnet272_a200_bn_cifar10':[4541.36,2.39],\n",
        "'pyramidnet200_a240_bn_cifar10':[4563.4,2.44],\n",
        "'pyramidnet164_a270_bn_cifar10':[4608.81,2.42],\n",
        "'pyramidnet236_a220_bn_cifar10':[4631.32,2.47],\n",
        "'pyramidnet110_a270_cifar10':[4730.6,2.51],\n",
        "'resnext272_2x32d_cifar10':[4867.11,2.74],\n",
        "'wrn40_8_cifar10':[5176.9,2.37],\n",
        "'wrn28_10_cifar10':[5246.98,2.39],\n",
        "'densenet100_k24_cifar10':[5354.19,3.13],\n",
        "'densenet40_k12_bc_cifar10':[5519.54,2.67],\n",
        "'resnext272_1x64d_cifar10':[6565.15,2.55],\n",
        "'densenet250_k24_bc_cifar10':[9400.45,2.52],\n",
        "'resnext29_16x64d_cifar10':[10709.34,2.41],}\n",
        "import random\n",
        "model_names=[]\n",
        "total_memory=0\n",
        "total_error=0\n",
        "\n",
        "model_list=list(model_dict.keys())\n",
        "'''\n",
        "random.shuffle(model_list)\n",
        "for m in model_list:\n",
        "\n",
        "    if model_dict[m][0]>1000 and len(model_names)<10:\n",
        "        print(model_dict[m][0])\n",
        "        continue\n",
        "    total_memory+=model_dict[m][0]\n",
        "    \n",
        "    if total_memory<=9000:\n",
        "        model_names.append(m)\n",
        "        total_error+=model_dict[m][1]\n",
        "    else:\n",
        "        total_memory-=model_dict[m][0]\n",
        "        break\n",
        "'''\n",
        "max_len=25\n",
        "for i,m in enumerate(model_list):\n",
        "    if i%2==0 and model_dict[m][1]<1000 and len(model_names)<max_len:\n",
        "        model_names.append(m)\n",
        "        total_error+=model_dict[m][1]\n",
        "        total_memory+=model_dict[m][0]\n",
        "best_model1=model_names\n",
        "'''\n",
        "model_names=['seresnet164bn_cifar10',\n",
        "'seresnet110_cifar10',\n",
        "'preresnet164bn_cifar10',\n",
        "'shakeshakeresnet26_2x32d_cifar10',\n",
        "'resnet164bn_cifar10',\n",
        "'resnet110_cifar10',\n",
        "'preresnet272bn_cifar10',\n",
        "'sepreresnet164bn_cifar10',\n",
        "'seresnet56_cifar10',\n",
        "'diaresnet164bn_cifar10',\n",
        "'resnet272bn_cifar10',\n",
        "'diapreresnet164bn_cifar10',\n",
        "'preresnet110_cifar10',\n",
        "'sepreresnet272bn_cifar10',\n",
        "'seresnet272bn_cifar10',\n",
        "'preresnet56_cifar10',\n",
        "'sepreresnet56_cifar10',\n",
        "'resnet56_cifar10',\n",
        "'diaresnet110_cifar10',\n",
        "'pyramidnet110_a48_cifar10',\n",
        "'ror3_164_cifar10',\n",
        "'diapreresnet110_cifar10',\n",
        "'densenet190_k40_bc_cifar10',\n",
        "'ror3_110_cifar10',\n",
        "'diapreresnet56_cifar10',\n",
        "'pyramidnet110_a84_cifar10',\n",
        "'sepreresnet110_cifar10',\n",
        "'shakeshakeresnet20_2x16d_cifar10',\n",
        "'resnext29_32x4d_cifar10',]\n",
        "'''\n",
        "#model_names=random.choices(model_names,k=20)\n",
        "print(model_names)\n",
        "print(len(model_names))\n",
        "print(\"total memory:\",total_memory)\n",
        "print(\"average error:\",total_error/len(model_names))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n",
            "['preresnet20_cifar10', 'seresnet20_cifar10', 'diapreresnet20_cifar10', 'densenet40_k12_cifar10', 'ror3_56_cifar10', 'resnet56_cifar10', 'sepreresnet56_cifar10', 'diaresnet56_cifar10', 'nin_cifar10', 'preresnet164bn_cifar10', 'preresnet110_cifar10', 'sepreresnet110_cifar10', 'sepreresnet164bn_cifar10', 'diapreresnet110_cifar10', 'densenet40_k24_bc_cifar10', 'densenet190_k40_bc_cifar10', 'diaresnet164bn_cifar10', 'pyramidnet110_a48_cifar10', 'resnet272bn_cifar10', 'seresnet272bn_cifar10', 'densenet40_k36_bc_cifar10', 'pyramidnet110_a84_cifar10', 'preresnet542bn_cifar10', 'sepreresnet542bn_cifar10', 'rir_cifar10']\n",
            "8778.79\n",
            "4.4588\n"
          ]
        }
      ],
      "source": [
        "total_memory=0\n",
        "total_error=0\n",
        "resnet_family=['densenet100_k12_cifar10',\n",
        "#'densenet100_k24_cifar10',\n",
        "'densenet100_k12_bc_cifar10',\n",
        "'densenet190_k40_bc_cifar10',\n",
        "'densenet250_k24_bc_cifar10',\n",
        "'densenet40_k12_bc_cifar10',\n",
        "'densenet40_k12_cifar10',\n",
        "'densenet40_k24_bc_cifar10',\n",
        "'densenet40_k36_bc_cifar10',\n",
        "'diapreresnet110_cifar10',\n",
        "'diapreresnet164bn_cifar10',\n",
        "'diapreresnet20_cifar10',\n",
        "'diapreresnet56_cifar10',\n",
        "'diaresnet110_cifar10',\n",
        "'diaresnet164bn_cifar10',\n",
        "'diaresnet20_cifar10',\n",
        "'diaresnet56_cifar10',\n",
        "'resnet272bn_cifar10',\n",
        "'resnet56_cifar10',\n",
        "'rir_cifar10',\n",
        "'ror3_164_cifar10',\n",
        "'sepreresnet110_cifar10',\n",
        "'sepreresnet164bn_cifar10',\n",
        "'sepreresnet20_cifar10',\n",
        "'sepreresnet272bn_cifar10',\n",
        "'sepreresnet542bn_cifar10',\n",
        "'sepreresnet56_cifar10',\n",
        "'seresnet110_cifar10',\n",
        "'seresnet164bn_cifar10',\n",
        "'seresnet20_cifar10',\n",
        "'seresnet272bn_cifar10',\n",
        "'seresnet542bn_cifar10',\n",
        "'seresnet56_cifar10',]\n",
        "#['', 'sepreresnet20_cifar10', '', '', 'sepreresnet56_cifar10', 'densenet100_k12_bc_cifar10', 'preresnet164bn_cifar10', '', 'sepreresnet164bn_cifar10', 'diaresnet110_cifar10', 'densenet190_k40_bc_cifar10', 'ror3_164_cifar10', 'resnet272bn_cifar10', 'shakeshakeresnet26_2x32d_cifar10', 'pyramidnet110_a84_cifar10', '', 'rir_cifar10', 'resnet1001\n",
        "model_index=[]\n",
        "for i,m in enumerate(model_list):\n",
        "    if m in model_names:\n",
        "    #if i<33:\n",
        "        total_memory+=model_dict[m][0]\n",
        "        total_error+=model_dict[m][1]\n",
        "        model_index.append(i)\n",
        "        \n",
        "print(len(model_names))\n",
        "print(model_names)\n",
        "print(total_memory)\n",
        "print(total_error/len(model_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "mode=\"error\"\n",
        "#####sort by loss######\n",
        "if mode==\"loss\":\n",
        "    model_dict={'preresnet20_cifar10': [41.27, 14.002521896362305], 'resnet20_cifar10': [41.29, 15.455768013000489], 'seresnet20_cifar10': [41.34, 12.153068504333497], 'sepreresnet20_cifar10': [41.35, 12.329749183654785], 'diapreresnet20_cifar10': [41.52, 11.258948059082032], 'diaresnet20_cifar10': [41.54, 9.293731651306153], 'densenet40_k12_cifar10': [74.89, 12.705183525085449], 'shakeshakeresnet20_2x16d_cifar10': [81.78, 10.11400177001953], 'ror3_56_cifar10': [113.43, 9.83536756515503], 'preresnet56_cifar10': [127.03, 11.35746124267578], 'resnet56_cifar10': [127.06, 11.712560501098633], 'seresnet56_cifar10': [127.19, 9.609673614501952], 'sepreresnet56_cifar10': [127.2, 10.337662391662597], 'diapreresnet56_cifar10': [129.28, 10.798598403930663], 'diaresnet56_cifar10': [129.31, 9.487401542663575], 'densenet100_k12_bc_cifar10': [210.8, 10.517892322540284], 'nin_cifar10': [222.97, 9.284525337219238], 'ror3_110_cifar10': [242.07, 8.537963504791259], 'preresnet164bn_cifar10': [255.08, 11.852857666015625], 'resnet164bn_cifar10': [255.31, 9.105857219696045], 'preresnet110_cifar10': [255.68, 11.42756929397583], 'resnet110_cifar10': [255.7, 11.505998649597167], 'sepreresnet110_cifar10': [255.98, 12.038713569641112], 'seresnet110_cifar10': [255.98, 10.485417442321777], 'sepreresnet164bn_cifar10': [256.32, 11.334516639709472], 'seresnet164bn_cifar10': [256.55, 9.558498840332032], 'diapreresnet110_cifar10': [264.69, 12.079894485473632], 'diaresnet110_cifar10': [264.71, 11.287718925476074], 'densenet40_k24_bc_cifar10': [293.09, 12.832738609313965], 'xdensenet40_2_k24_bc_cifar10': [293.09, 13.962934150695801], 'densenet190_k40_bc_cifar10': [298.45, 11.011504554748536], 'diapreresnet164bn_cifar10': [343.37, 9.987324905395507], 'diaresnet164bn_cifar10': [343.6, 11.863894233703613], 'ror3_164_cifar10': [370.72, 10.107543544769287], 'pyramidnet110_a48_cifar10': [408.37, 13.034896545410156], 'preresnet272bn_cifar10': [420.38, 10.406990242004394], 'resnet272bn_cifar10': [420.61, 12.495949745178223], 'sepreresnet272bn_cifar10': [422.45, 12.36975715637207], 'seresnet272bn_cifar10': [422.68, 8.959838218688965], 'shakeshakeresnet26_2x32d_cifar10': [428.89, 10.126092185974121], 'densenet40_k36_bc_cifar10': [654.6, 10.228862380981445], 'xdensenet40_2_k36_bc_cifar10': [654.6, 9.984689674377442], 'pyramidnet110_a84_cifar10': [778.15, 14.02359088897705], 'resnext29_32x4d_cifar10': [780.55, 17.76765525817871], 'preresnet542bn_cifar10': [833.64, 9.7698171043396], 'resnet542bn_cifar10': [833.87, 9.412583045959472], 'sepreresnet542bn_cifar10': [837.78, 10.032699031829834], 'seresnet542bn_cifar10': [838.01, 10.542131252288819], 'rir_cifar10': [1281.08, 12.140970497131347], 'densenet100_k12_cifar10': [1353.55, 11.513689994812012], 'preresnet1001_cifar10': [1536.18, 9.667638549804687], 'resnet1001_cifar10': [1536.4, 10.535249824523925], 'wrn16_10_cifar10': [2414.04, 15.17474723815918], 'preresnet1202_cifar10': [2857.14, 9.817216911315917], 'resnet1202_cifar10': [2857.17, 8.871091079711913], 'wrn20_10_1bit_cifar10': [4019.14, 15.239664878845215], 'wrn20_10_32bit_cifar10': [4019.14, 13.293598175048828], 'pyramidnet272_a200_bn_cifar10': [4541.36, 11.890794334411622], 'pyramidnet200_a240_bn_cifar10': [4563.4, 11.384682960510254], 'pyramidnet164_a270_bn_cifar10': [4608.81, 11.562754898071288], 'pyramidnet236_a220_bn_cifar10': [4631.32, 12.45128273010254], 'pyramidnet110_a270_cifar10': [4730.6, 18.649833183288575], 'resnext272_2x32d_cifar10': [4867.11, 11.92292751312256], 'wrn40_8_cifar10': [5176.9, 12.256089820861817], 'wrn28_10_cifar10': [5246.98, 16.313759994506835], 'densenet100_k24_cifar10': [5354.19, 12.105612030029297], 'densenet40_k12_bc_cifar10': [5519.54, 16.207676773071288], 'resnext272_1x64d_cifar10': [6565.15, 11.917600746154784], 'densenet250_k24_bc_cifar10': [9400.45, 12.131968269348144], 'resnext29_16x64d_cifar10': [10709.34, 10.799761257171632]}\n",
        "elif mode==\"acc\":\n",
        "    model_dict={'preresnet20_cifar10': [41.27, 0.0], 'resnet20_cifar10': [41.29, 0.0], 'seresnet20_cifar10': [41.34, 0.01], 'sepreresnet20_cifar10': [41.35, 0.02], 'diapreresnet20_cifar10': [41.52, 0.02], 'diaresnet20_cifar10': [41.54, 0.005], 'densenet40_k12_cifar10': [74.89, 0.0], 'shakeshakeresnet20_2x16d_cifar10': [81.78, 0.01], 'ror3_56_cifar10': [113.43, 0.0], 'preresnet56_cifar10': [127.03, 0.015], 'resnet56_cifar10': [127.06, 0.01], 'seresnet56_cifar10': [127.19, 0.01], 'sepreresnet56_cifar10': [127.2, 0.015], 'diapreresnet56_cifar10': [129.28, 0.06], 'diaresnet56_cifar10': [129.31, 0.02], 'densenet100_k12_bc_cifar10': [210.8, 0.005], 'nin_cifar10': [222.97, 0.0], 'ror3_110_cifar10': [242.07, 0.02], 'preresnet164bn_cifar10': [255.08, 0.03], 'resnet164bn_cifar10': [255.31, 0.0], 'preresnet110_cifar10': [255.68, 0.045], 'resnet110_cifar10': [255.7, 0.01], 'sepreresnet110_cifar10': [255.98, 0.0], 'seresnet110_cifar10': [255.98, 0.025], 'sepreresnet164bn_cifar10': [256.32, 0.075], 'seresnet164bn_cifar10': [256.55, 0.01], 'diapreresnet110_cifar10': [264.69, 0.065], 'diaresnet110_cifar10': [264.71, 0.01], 'densenet40_k24_bc_cifar10': [293.09, 0.01], 'xdensenet40_2_k24_bc_cifar10': [293.09, 0.01], 'densenet190_k40_bc_cifar10': [298.45, 0.02], 'diapreresnet164bn_cifar10': [343.37, 0.105], 'diaresnet164bn_cifar10': [343.6, 0.035], 'ror3_164_cifar10': [370.72, 0.045], 'pyramidnet110_a48_cifar10': [408.37, 0.025], 'preresnet272bn_cifar10': [420.38, 0.075], 'resnet272bn_cifar10': [420.61, 0.015], 'sepreresnet272bn_cifar10': [422.45, 0.045], 'seresnet272bn_cifar10': [422.68, 0.105], 'shakeshakeresnet26_2x32d_cifar10': [428.89, 0.0], 'densenet40_k36_bc_cifar10': [654.6, 0.0], 'xdensenet40_2_k36_bc_cifar10': [654.6, 0.0], 'pyramidnet110_a84_cifar10': [778.15, 0.04], 'resnext29_32x4d_cifar10': [780.55, 0.0], 'preresnet542bn_cifar10': [833.64, 0.145], 'resnet542bn_cifar10': [833.87, 0.12], 'sepreresnet542bn_cifar10': [837.78, 0.14], 'seresnet542bn_cifar10': [838.01, 0.08], 'rir_cifar10': [1281.08, 0.015], 'densenet100_k12_cifar10': [1353.55, 0.025], 'preresnet1001_cifar10': [1536.18, 0.105], 'resnet1001_cifar10': [1536.4, 0.09], 'wrn16_10_cifar10': [2414.04, 0.005], 'preresnet1202_cifar10': [2857.14, 0.085], 'resnet1202_cifar10': [2857.17, 0.14], 'wrn20_10_1bit_cifar10': [4019.14, 0.005], 'wrn20_10_32bit_cifar10': [4019.14, 0.0], 'pyramidnet272_a200_bn_cifar10': [4541.36, 0.005], 'pyramidnet200_a240_bn_cifar10': [4563.4, 0.015], 'pyramidnet164_a270_bn_cifar10': [4608.81, 0.005], 'pyramidnet236_a220_bn_cifar10': [4631.32, 0.005], 'pyramidnet110_a270_cifar10': [4730.6, 0.045], 'resnext272_2x32d_cifar10': [4867.11, 0.07], 'wrn40_8_cifar10': [5176.9, 0.035], 'wrn28_10_cifar10': [5246.98, 0.005], 'densenet100_k24_cifar10': [5354.19, 0.05], 'densenet40_k12_bc_cifar10': [5519.54, 0.0], 'resnext272_1x64d_cifar10': [6565.15, 0.095], 'densenet250_k24_bc_cifar10': [9400.45, 0.12], 'resnext29_16x64d_cifar10': [10709.34, 0.0]}\n",
        "elif mode==\"error\":\n",
        "    model_dict={'preresnet20_cifar10': [41.27, 6.51], 'resnet20_cifar10': [41.29, 5.97], 'seresnet20_cifar10': [41.34, 6.01], 'sepreresnet20_cifar10': [41.35, 6.18], 'diapreresnet20_cifar10': [41.52, 6.42], 'diaresnet20_cifar10': [41.54, 6.22], 'densenet40_k12_cifar10': [74.89, 6.43], 'shakeshakeresnet20_2x16d_cifar10': [81.78, 5.15], 'ror3_56_cifar10': [113.43, 5.43], 'preresnet56_cifar10': [127.03, 4.49], 'resnet56_cifar10': [127.06, 4.52], 'seresnet56_cifar10': [127.19, 4.13], 'sepreresnet56_cifar10': [127.2, 4.51], 'diapreresnet56_cifar10': [129.28, 4.83], 'diaresnet56_cifar10': [129.31, 5.05], 'densenet100_k12_bc_cifar10': [210.8, 5.61], 'nin_cifar10': [222.97, 7.43], 'ror3_110_cifar10': [242.07, 4.35], 'preresnet164bn_cifar10': [255.08, 3.64], 'resnet164bn_cifar10': [255.31, 3.68], 'preresnet110_cifar10': [255.68, 3.86], 'resnet110_cifar10': [255.7, 3.69], 'sepreresnet110_cifar10': [255.98, 4.54], 'seresnet110_cifar10': [255.98, 3.63], 'sepreresnet164bn_cifar10': [256.32, 3.73], 'seresnet164bn_cifar10': [256.55, 3.39], 'diapreresnet110_cifar10': [264.69, 4.25], 'diaresnet110_cifar10': [264.71, 4.1], 'densenet40_k24_bc_cifar10': [293.09, 4.52], 'xdensenet40_2_k24_bc_cifar10': [293.09, 5.31], 'densenet190_k40_bc_cifar10': [298.45, 4.16], 'diapreresnet164bn_cifar10': [343.37, 3.56], 'diaresnet164bn_cifar10': [343.6, 3.5], 'ror3_164_cifar10': [370.72, 3.93], 'pyramidnet110_a48_cifar10': [408.37, 3.72], 'preresnet272bn_cifar10': [420.38, 3.25], 'resnet272bn_cifar10': [420.61, 3.33], 'sepreresnet272bn_cifar10': [422.45, 3.39], 'seresnet272bn_cifar10': [422.68, 3.39], 'shakeshakeresnet26_2x32d_cifar10': [428.89, 3.17], 'densenet40_k36_bc_cifar10': [654.6, 4.04], 'xdensenet40_2_k36_bc_cifar10': [654.6, 4.37], 'pyramidnet110_a84_cifar10': [778.15, 2.98], 'resnext29_32x4d_cifar10': [780.55, 3.15], 'preresnet542bn_cifar10': [833.64, 3.14], 'resnet542bn_cifar10': [833.87, 3.43], 'sepreresnet542bn_cifar10': [837.78, 3.08], 'seresnet542bn_cifar10': [838.01, 3.47], 'rir_cifar10': [1281.08, 3.28], 'densenet100_k12_cifar10': [1353.55, 3.66], 'preresnet1001_cifar10': [1536.18, 2.65], 'resnet1001_cifar10': [1536.4, 3.28], 'wrn16_10_cifar10': [2414.04, 2.93], 'preresnet1202_cifar10': [2857.14, 3.39], 'resnet1202_cifar10': [2857.17, 3.53], 'wrn20_10_1bit_cifar10': [4019.14, 3.26], 'wrn20_10_32bit_cifar10': [4019.14, 3.14], 'pyramidnet272_a200_bn_cifar10': [4541.36, 2.39], 'pyramidnet200_a240_bn_cifar10': [4563.4, 2.44], 'pyramidnet164_a270_bn_cifar10': [4608.81, 2.42], 'pyramidnet236_a220_bn_cifar10': [4631.32, 2.47], 'pyramidnet110_a270_cifar10': [4730.6, 2.51], 'resnext272_2x32d_cifar10': [4867.11, 2.74], 'wrn40_8_cifar10': [5176.9, 2.37], 'wrn28_10_cifar10': [5246.98, 2.39], 'densenet100_k24_cifar10': [5354.19, 3.13], 'densenet40_k12_bc_cifar10': [5519.54, 2.67], 'resnext272_1x64d_cifar10': [6565.15, 2.55], 'densenet250_k24_bc_cifar10': [9400.45, 2.52], 'resnext29_16x64d_cifar10': [10709.34, 2.41]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('wrn40_8_cifar10', [5176.9, 2.37]), ('pyramidnet272_a200_bn_cifar10', [4541.36, 2.39]), ('wrn28_10_cifar10', [5246.98, 2.39]), ('resnext29_16x64d_cifar10', [10709.34, 2.41]), ('pyramidnet164_a270_bn_cifar10', [4608.81, 2.42]), ('pyramidnet200_a240_bn_cifar10', [4563.4, 2.44]), ('pyramidnet236_a220_bn_cifar10', [4631.32, 2.47]), ('pyramidnet110_a270_cifar10', [4730.6, 2.51]), ('densenet250_k24_bc_cifar10', [9400.45, 2.52]), ('resnext272_1x64d_cifar10', [6565.15, 2.55]), ('preresnet1001_cifar10', [1536.18, 2.65]), ('densenet40_k12_bc_cifar10', [5519.54, 2.67]), ('resnext272_2x32d_cifar10', [4867.11, 2.74]), ('wrn16_10_cifar10', [2414.04, 2.93]), ('pyramidnet110_a84_cifar10', [778.15, 2.98]), ('sepreresnet542bn_cifar10', [837.78, 3.08]), ('densenet100_k24_cifar10', [5354.19, 3.13]), ('preresnet542bn_cifar10', [833.64, 3.14]), ('wrn20_10_32bit_cifar10', [4019.14, 3.14]), ('resnext29_32x4d_cifar10', [780.55, 3.15]), ('shakeshakeresnet26_2x32d_cifar10', [428.89, 3.17]), ('preresnet272bn_cifar10', [420.38, 3.25]), ('wrn20_10_1bit_cifar10', [4019.14, 3.26]), ('rir_cifar10', [1281.08, 3.28]), ('resnet1001_cifar10', [1536.4, 3.28]), ('resnet272bn_cifar10', [420.61, 3.33]), ('seresnet164bn_cifar10', [256.55, 3.39]), ('sepreresnet272bn_cifar10', [422.45, 3.39]), ('seresnet272bn_cifar10', [422.68, 3.39]), ('preresnet1202_cifar10', [2857.14, 3.39]), ('resnet542bn_cifar10', [833.87, 3.43]), ('seresnet542bn_cifar10', [838.01, 3.47]), ('diaresnet164bn_cifar10', [343.6, 3.5]), ('resnet1202_cifar10', [2857.17, 3.53]), ('diapreresnet164bn_cifar10', [343.37, 3.56]), ('seresnet110_cifar10', [255.98, 3.63]), ('preresnet164bn_cifar10', [255.08, 3.64]), ('densenet100_k12_cifar10', [1353.55, 3.66]), ('resnet164bn_cifar10', [255.31, 3.68]), ('resnet110_cifar10', [255.7, 3.69]), ('pyramidnet110_a48_cifar10', [408.37, 3.72]), ('sepreresnet164bn_cifar10', [256.32, 3.73]), ('preresnet110_cifar10', [255.68, 3.86]), ('ror3_164_cifar10', [370.72, 3.93]), ('densenet40_k36_bc_cifar10', [654.6, 4.04]), ('diaresnet110_cifar10', [264.71, 4.1]), ('seresnet56_cifar10', [127.19, 4.13]), ('densenet190_k40_bc_cifar10', [298.45, 4.16]), ('diapreresnet110_cifar10', [264.69, 4.25]), ('ror3_110_cifar10', [242.07, 4.35]), ('xdensenet40_2_k36_bc_cifar10', [654.6, 4.37]), ('preresnet56_cifar10', [127.03, 4.49]), ('sepreresnet56_cifar10', [127.2, 4.51]), ('resnet56_cifar10', [127.06, 4.52]), ('densenet40_k24_bc_cifar10', [293.09, 4.52]), ('sepreresnet110_cifar10', [255.98, 4.54]), ('diapreresnet56_cifar10', [129.28, 4.83]), ('diaresnet56_cifar10', [129.31, 5.05]), ('shakeshakeresnet20_2x16d_cifar10', [81.78, 5.15]), ('xdensenet40_2_k24_bc_cifar10', [293.09, 5.31]), ('ror3_56_cifar10', [113.43, 5.43]), ('densenet100_k12_bc_cifar10', [210.8, 5.61]), ('resnet20_cifar10', [41.29, 5.97]), ('seresnet20_cifar10', [41.34, 6.01]), ('sepreresnet20_cifar10', [41.35, 6.18]), ('diaresnet20_cifar10', [41.54, 6.22]), ('diapreresnet20_cifar10', [41.52, 6.42]), ('densenet40_k12_cifar10', [74.89, 6.43]), ('preresnet20_cifar10', [41.27, 6.51]), ('nin_cifar10', [222.97, 7.43])]\n",
            "densenet190_k40_bc_cifar10\n",
            "densenet40_k24_bc_cifar10\n",
            "densenet40_k36_bc_cifar10\n",
            "diapreresnet110_cifar10\n",
            "diapreresnet164bn_cifar10\n",
            "diaresnet110_cifar10\n",
            "diaresnet164bn_cifar10\n",
            "preresnet110_cifar10\n",
            "preresnet164bn_cifar10\n",
            "preresnet272bn_cifar10\n",
            "preresnet542bn_cifar10\n",
            "preresnet56_cifar10\n",
            "pyramidnet110_a48_cifar10\n",
            "pyramidnet110_a84_cifar10\n",
            "resnet110_cifar10\n",
            "resnet164bn_cifar10\n",
            "resnet272bn_cifar10\n",
            "resnet542bn_cifar10\n",
            "resnet56_cifar10\n",
            "resnext29_32x4d_cifar10\n",
            "ror3_110_cifar10\n",
            "ror3_164_cifar10\n",
            "sepreresnet110_cifar10\n",
            "sepreresnet164bn_cifar10\n",
            "sepreresnet272bn_cifar10\n",
            "sepreresnet542bn_cifar10\n",
            "sepreresnet56_cifar10\n",
            "seresnet110_cifar10\n",
            "seresnet164bn_cifar10\n",
            "seresnet272bn_cifar10\n",
            "seresnet542bn_cifar10\n",
            "seresnet56_cifar10\n",
            "shakeshakeresnet26_2x32d_cifar10\n",
            "xdensenet40_2_k36_bc_cifar10\n"
          ]
        }
      ],
      "source": [
        "#print(list(model_dict.items())[0][0])\n",
        "model_list=list(model_dict.items())\n",
        "#print(model_list[1][1][1])\n",
        "model_list=sorted(model_list,key=lambda x:x[1][1],reverse=False)\n",
        "print(model_list)\n",
        "model_list_less_1000=[]\n",
        "model_list_high_cp=[]\n",
        "model_names=[]\n",
        "total_memory=0\n",
        "for m in model_list:\n",
        "    \n",
        "    if m[1][0]>1500:continue\n",
        "    total_memory+=m[1][0]\n",
        "    #print(total_memory)\n",
        "    #print(total_memory)\n",
        "    if m[1][0]<1500 and total_memory<14000:\n",
        "        model_list_high_cp.append(m[0])\n",
        "    if m[1][0]<1000 and len(model_list_less_1000)<45:\n",
        "        model_list_less_1000.append(m[0])\n",
        "    if i%2==0 or m[1][0]>1000 or len(model_names)>33:\n",
        "        continue\n",
        "    model_names.append(m[0])\n",
        "best_model2=model_names\n",
        "#print(model_names)\n",
        "#print(model_dict)\n",
        "max_slice=23\n",
        "model_names=model_names[1:max_slice]\n",
        "for m in resnet_family:\n",
        "    if len(model_names)>=30:\n",
        "        break\n",
        "    if m not in model_names:\n",
        "        model_names.append(m)\n",
        "#print(model_names)\n",
        "##################test ensemble model###################\n",
        "#model_names=resnet_family\n",
        "def calculator(model_names,model_list):\n",
        "    global model_dict\n",
        "    total_memory=0\n",
        "    total_error=0\n",
        "    model_index=[]\n",
        "    for i,m in enumerate(model_list):\n",
        "        \n",
        "        m=m[0]\n",
        "        #print(\"mmm:\",m,model_names)\n",
        "        if m in model_names:\n",
        "            #print(\"Test\")\n",
        "            #print(model_dict[m])\n",
        "        #if i<33:\n",
        "            #print(model_dict[m][0])\n",
        "            total_memory+=model_dict[m][0]\n",
        "            total_error+=model_dict[m][1]\n",
        "            model_index.append(i)\n",
        "    return total_memory,total_error\n",
        "best_model2=sorted(best_model2)\n",
        "for m in best_model2:\n",
        "    print(m)\n",
        "#print(model_names)\n",
        "#print(len(model_names))\n",
        "#print(total_memory)\n",
        "#print(total_error/len(model_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n",
            "pyramidnet110_a84_cifar10\n",
            "sepreresnet542bn_cifar10\n",
            "preresnet542bn_cifar10\n",
            "resnext29_32x4d_cifar10\n",
            "shakeshakeresnet26_2x32d_cifar10\n",
            "preresnet272bn_cifar10\n",
            "rir_cifar10\n",
            "resnet272bn_cifar10\n",
            "seresnet164bn_cifar10\n",
            "sepreresnet272bn_cifar10\n",
            "seresnet272bn_cifar10\n",
            "resnet542bn_cifar10\n",
            "seresnet542bn_cifar10\n",
            "diaresnet164bn_cifar10\n",
            "diapreresnet164bn_cifar10\n",
            "seresnet110_cifar10\n",
            "preresnet164bn_cifar10\n",
            "densenet100_k12_cifar10\n",
            "resnet164bn_cifar10\n",
            "resnet110_cifar10\n",
            "pyramidnet110_a48_cifar10\n",
            "sepreresnet164bn_cifar10\n",
            "preresnet110_cifar10\n",
            "ror3_164_cifar10\n",
            "densenet40_k36_bc_cifar10\n",
            "diaresnet110_cifar10\n",
            "seresnet56_cifar10\n"
          ]
        }
      ],
      "source": [
        "#model_list_high_cp=sorted(model_list_high_cp)\n",
        "print(len(model_list_high_cp))\n",
        "for m in model_list_high_cp:\n",
        "    print(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## iteration get the fgsm loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nfrom pytorchcv.model_provider import get_model as ptcv_get_model\\nfor m in model_list:\\n    model_name = m\\n    model_checker(model_name)\\n\\n    model = ptcv_get_model(model_name, pretrained=True).to(device)\\n    loss_fn = nn.CrossEntropyLoss()\\n    benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\\n    adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\\n    model_dict[m][1]=fgsm_acc\\n    #print(m,adv_examples)\\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
        "for m in model_list:\n",
        "    model_name = m\n",
        "    model_checker(model_name)\n",
        "\n",
        "    model = ptcv_get_model(model_name, pretrained=True).to(device)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
        "    adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\n",
        "    model_dict[m][1]=fgsm_acc\n",
        "    #print(m,adv_examples)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25\n",
            "['preresnet20_cifar10', 'seresnet20_cifar10', 'diapreresnet20_cifar10', 'densenet40_k12_cifar10', 'ror3_56_cifar10', 'resnet56_cifar10', 'sepreresnet56_cifar10', 'diaresnet56_cifar10', 'nin_cifar10', 'preresnet164bn_cifar10', 'preresnet110_cifar10', 'sepreresnet110_cifar10', 'sepreresnet164bn_cifar10', 'diapreresnet110_cifar10', 'densenet40_k24_bc_cifar10', 'densenet190_k40_bc_cifar10', 'diaresnet164bn_cifar10', 'pyramidnet110_a48_cifar10', 'resnet272bn_cifar10', 'seresnet272bn_cifar10', 'densenet40_k36_bc_cifar10', 'pyramidnet110_a84_cifar10', 'preresnet542bn_cifar10', 'sepreresnet542bn_cifar10', 'rir_cifar10']\n",
            "34\n",
            "['densenet190_k40_bc_cifar10', 'densenet40_k24_bc_cifar10', 'densenet40_k36_bc_cifar10', 'diapreresnet110_cifar10', 'diapreresnet164bn_cifar10', 'diaresnet110_cifar10', 'diaresnet164bn_cifar10', 'preresnet110_cifar10', 'preresnet164bn_cifar10', 'preresnet272bn_cifar10', 'preresnet542bn_cifar10', 'preresnet56_cifar10', 'pyramidnet110_a48_cifar10', 'pyramidnet110_a84_cifar10', 'resnet110_cifar10', 'resnet164bn_cifar10', 'resnet272bn_cifar10', 'resnet542bn_cifar10', 'resnet56_cifar10', 'resnext29_32x4d_cifar10', 'ror3_110_cifar10', 'ror3_164_cifar10', 'sepreresnet110_cifar10', 'sepreresnet164bn_cifar10', 'sepreresnet272bn_cifar10', 'sepreresnet542bn_cifar10', 'sepreresnet56_cifar10', 'seresnet110_cifar10', 'seresnet164bn_cifar10', 'seresnet272bn_cifar10', 'seresnet542bn_cifar10', 'seresnet56_cifar10', 'shakeshakeresnet26_2x32d_cifar10', 'xdensenet40_2_k36_bc_cifar10']\n",
            "42\n",
            "['densenet190_k40_bc_cifar10', 'densenet40_k24_bc_cifar10', 'densenet40_k36_bc_cifar10', 'diapreresnet110_cifar10', 'diapreresnet164bn_cifar10', 'diaresnet110_cifar10', 'diaresnet164bn_cifar10', 'preresnet110_cifar10', 'preresnet164bn_cifar10', 'preresnet272bn_cifar10', 'preresnet542bn_cifar10', 'preresnet56_cifar10', 'pyramidnet110_a48_cifar10', 'pyramidnet110_a84_cifar10', 'resnet110_cifar10', 'resnet164bn_cifar10', 'resnet272bn_cifar10', 'resnet542bn_cifar10', 'resnet56_cifar10', 'resnext29_32x4d_cifar10', 'ror3_110_cifar10', 'ror3_164_cifar10', 'sepreresnet110_cifar10', 'sepreresnet164bn_cifar10', 'sepreresnet272bn_cifar10', 'sepreresnet542bn_cifar10', 'sepreresnet56_cifar10', 'seresnet110_cifar10', 'seresnet164bn_cifar10', 'seresnet272bn_cifar10', 'seresnet542bn_cifar10', 'seresnet56_cifar10', 'shakeshakeresnet26_2x32d_cifar10', 'xdensenet40_2_k36_bc_cifar10', 'densenet190_k40_bc_cifar10', 'densenet40_k24_bc_cifar10', 'densenet40_k36_bc_cifar10', 'diapreresnet110_cifar10', 'diapreresnet164bn_cifar10', 'preresnet110_cifar10', 'preresnet164bn_cifar10', 'sepreresnet272bn_cifar10']\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "print(len(best_model1))\n",
        "print(best_model1)\n",
        "print(len(best_model2))\n",
        "print(best_model2)\n",
        "merge_model=copy.deepcopy(best_model2)\n",
        "for i,m in enumerate(best_model1):\n",
        "    if m  not in merge_model and len(merge_model)<50:\n",
        "        merge_model.append(best_model2[i])\n",
        "print(len(merge_model))\n",
        "print(merge_model)\n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-CWEsxsUD0Mo"
      },
      "source": [
        "## FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP6s-MCODyyh",
        "outputId": "712b343f-da52-4401-ffca-3837231fef6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ncreate_dir(root, \\'mifgsm\\', adv_examples, adv_names)\\nprint(len(model_names))\\nprint(\"mmode:\",mode)\\nprint(\"max slice:\",max_slice)\\nprint(\"model index:\",model_index)\\nprint(\"total memory:\",total_memory)\\nprint(\"average loss:\",total_error/len(model_names))\\nprint(\"alpha\",alpha)\\n'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "from datetime import datetime\n",
        "t=str(datetime.now())\n",
        "f=open('log/'+t+'.txt','a+')\n",
        "best_loss=0\n",
        "best_index=[]\n",
        "best_name=''\n",
        "epoch=0\n",
        "fgsm_acc=0\n",
        "fgsm_loss=0\n",
        "print(f'mifgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}',model_index,model_names,file=f)\n",
        "print(f'mifgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}',model_index,model_names)\n",
        "while True:\n",
        "\n",
        "    \n",
        "    model_names = random.choices(model_list,k=25)\n",
        "    temp=[]\n",
        "    for m in model_names:\n",
        "        temp.append(m[0])\n",
        "    model_names=temp\n",
        "    #print(model_names)\n",
        "\n",
        "    mem,loss=calculator(model_names,model_list)\n",
        "\n",
        "    if mem>7500:continue\n",
        "    if epoch==60:break\n",
        "    try:\n",
        "        \n",
        "        model = ensembleNet(model_names).to(device)\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
        "\n",
        "        #print(\"Start\")\n",
        "        adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\n",
        "        if fgsm_loss>best_loss:\n",
        "            best_loss=fgsm_loss\n",
        "            best_index=model_index\n",
        "            best_name=model_names\n",
        "        \n",
        "    except:\n",
        "        #print(\"end\")\n",
        "        continue\n",
        "    #print(f'mifgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}'+model_index+model_names)\n",
        "        \n",
        "    print(\"epoch:\",epoch)\n",
        "    epoch+=1\n",
        "    print(f'mifgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}',model_index,model_names,file=f)\n",
        "    print(f'mifgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}',model_index,model_names)\n",
        "    print(mem,loss)\n",
        "print(best_loss)\n",
        "print(best_index)\n",
        "print(best_name)\n",
        "'''\n",
        "'''\n",
        "create_dir(root, 'mifgsm', adv_examples, adv_names)\n",
        "print(len(model_names))\n",
        "print(\"mmode:\",mode)\n",
        "print(\"max slice:\",max_slice)\n",
        "print(\"model index:\",model_index)\n",
        "print(\"total memory:\",total_memory)\n",
        "print(\"average loss:\",total_error/len(model_names))\n",
        "print(\"alpha\",alpha)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "#print(best_loss)\n",
        "#print(best_index)\n",
        "#print(best_name)\n",
        "#best_name=sorted(best_name)\n",
        "#mem,loss=calculator(best_name,model_list)\n",
        "#print(mem,loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13954.82, 95.32000000000002)\n"
          ]
        }
      ],
      "source": [
        "#model_names=random.choices(merge_model,k=23)\n",
        "#print(len(model_names))\n",
        "print(calculator(model_list_high_cp,model_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['pyramidnet110_a84_cifar10', 'sepreresnet542bn_cifar10', 'preresnet542bn_cifar10', 'resnext29_32x4d_cifar10', 'shakeshakeresnet26_2x32d_cifar10', 'preresnet272bn_cifar10', 'rir_cifar10', 'resnet272bn_cifar10', 'seresnet164bn_cifar10', 'sepreresnet272bn_cifar10', 'seresnet272bn_cifar10', 'resnet542bn_cifar10', 'seresnet542bn_cifar10', 'diaresnet164bn_cifar10', 'diapreresnet164bn_cifar10', 'seresnet110_cifar10', 'preresnet164bn_cifar10', 'densenet100_k12_cifar10', 'resnet164bn_cifar10', 'resnet110_cifar10', 'pyramidnet110_a48_cifar10', 'sepreresnet164bn_cifar10', 'preresnet110_cifar10', 'ror3_164_cifar10', 'densenet40_k36_bc_cifar10', 'diaresnet110_cifar10', 'seresnet56_cifar10']\n"
          ]
        }
      ],
      "source": [
        "print(model_list_high_cp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_2883244/2527319711.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbenign_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbenign_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_benign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madv_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_2883244/1974302512.py\u001b[0m in \u001b[0;36mepoch_benign\u001b[0;34m(model, loader, loss_fn)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0myp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0myp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_2883244/3826497583.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0;31m#print(self.model_names[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           \u001b[0mensemble_logits\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mensemble_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensemble_logits\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# TODO: sum up logits from multiple models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/pytorchcv/models/preresnet_cifar.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/pytorchcv/models/preresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pre_activ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_identity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pre_activ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/pytorchcv/models/preresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pre_activ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/pytorchcv/models/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 995\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mbn_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mexponential_average_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/py37DRL/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2439\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2440\u001b[0m     )\n\u001b[1;32m   2441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "#model_names = best_name\n",
        "\n",
        "model_names=model_list_high_cp\n",
        "#model_names=random.choices(resnet_family,k=27)\n",
        "print(len(model_names))\n",
        "model = ensembleNet(model_names).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "benign_acc, benign_loss = epoch_benign(model, adv_loader, loss_fn)\n",
        "\n",
        "\n",
        "adv_examples, fgsm_acc, fgsm_loss = gen_adv_examples(model, adv_loader, mifgsm, loss_fn)\n",
        "print(f'mifgsm_acc = {fgsm_acc:.5f}, fgsm_loss = {fgsm_loss:.5f}')\n",
        "\n",
        "\n",
        "\n",
        "create_dir(root, 'mifgsm', adv_examples, adv_names)\n",
        "print(len(model_names))\n",
        "print(\"mmode:\",mode)\n",
        "print(\"max slice:\",max_slice)\n",
        "print(\"model index:\",model_index)\n",
        "print(\"total memory:\",total_memory)\n",
        "print(\"average loss:\",total_error/len(model_names))\n",
        "print(\"alpha\",alpha)\n",
        "%cd mifgsm\n",
        "!tar zcvf ../mifgsm.tgz *\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('densenet100_k12_cifar10', [1353.55, 3.66])\n",
            "('densenet40_k36_bc_cifar10', [654.6, 4.04])\n",
            "('diapreresnet164bn_cifar10', [343.37, 3.56])\n",
            "('diaresnet110_cifar10', [264.71, 4.1])\n",
            "('diaresnet164bn_cifar10', [343.6, 3.5])\n",
            "('preresnet110_cifar10', [255.68, 3.86])\n",
            "('preresnet164bn_cifar10', [255.08, 3.64])\n",
            "('preresnet272bn_cifar10', [420.38, 3.25])\n",
            "('preresnet542bn_cifar10', [833.64, 3.14])\n",
            "('pyramidnet110_a48_cifar10', [408.37, 3.72])\n",
            "('pyramidnet110_a84_cifar10', [778.15, 2.98])\n",
            "('resnet110_cifar10', [255.7, 3.69])\n",
            "('resnet164bn_cifar10', [255.31, 3.68])\n",
            "('resnet272bn_cifar10', [420.61, 3.33])\n",
            "('resnet542bn_cifar10', [833.87, 3.43])\n",
            "('resnext29_32x4d_cifar10', [780.55, 3.15])\n",
            "('rir_cifar10', [1281.08, 3.28])\n",
            "('ror3_164_cifar10', [370.72, 3.93])\n",
            "('sepreresnet164bn_cifar10', [256.32, 3.73])\n",
            "('sepreresnet272bn_cifar10', [422.45, 3.39])\n",
            "('sepreresnet542bn_cifar10', [837.78, 3.08])\n",
            "('seresnet110_cifar10', [255.98, 3.63])\n",
            "('seresnet164bn_cifar10', [256.55, 3.39])\n",
            "('seresnet272bn_cifar10', [422.68, 3.39])\n",
            "('seresnet542bn_cifar10', [838.01, 3.47])\n",
            "('seresnet56_cifar10', [127.19, 4.13])\n",
            "('shakeshakeresnet26_2x32d_cifar10', [428.89, 3.17])\n"
          ]
        }
      ],
      "source": [
        "model_names=sorted(model_names)\n",
        "for m in model_names:\n",
        "    print(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70\n"
          ]
        }
      ],
      "source": [
        "print(len(model_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('densenet100_k12_cifar10', [1353.55, 3.66])\n",
            "('densenet40_k36_bc_cifar10', [654.6, 4.04])\n",
            "('diapreresnet164bn_cifar10', [343.37, 3.56])\n",
            "('diaresnet110_cifar10', [264.71, 4.1])\n",
            "('diaresnet164bn_cifar10', [343.6, 3.5])\n",
            "('preresnet110_cifar10', [255.68, 3.86])\n",
            "('preresnet164bn_cifar10', [255.08, 3.64])\n",
            "('preresnet272bn_cifar10', [420.38, 3.25])\n",
            "('preresnet542bn_cifar10', [833.64, 3.14])\n",
            "('pyramidnet110_a48_cifar10', [408.37, 3.72])\n",
            "('pyramidnet110_a84_cifar10', [778.15, 2.98])\n",
            "('resnet110_cifar10', [255.7, 3.69])\n",
            "('resnet164bn_cifar10', [255.31, 3.68])\n",
            "('resnet272bn_cifar10', [420.61, 3.33])\n",
            "('resnet542bn_cifar10', [833.87, 3.43])\n",
            "('resnext29_32x4d_cifar10', [780.55, 3.15])\n",
            "('rir_cifar10', [1281.08, 3.28])\n",
            "('ror3_164_cifar10', [370.72, 3.93])\n",
            "('sepreresnet164bn_cifar10', [256.32, 3.73])\n",
            "('sepreresnet272bn_cifar10', [422.45, 3.39])\n",
            "('sepreresnet542bn_cifar10', [837.78, 3.08])\n",
            "('seresnet110_cifar10', [255.98, 3.63])\n",
            "('seresnet164bn_cifar10', [256.55, 3.39])\n",
            "('seresnet272bn_cifar10', [422.68, 3.39])\n",
            "('seresnet542bn_cifar10', [838.01, 3.47])\n",
            "('seresnet56_cifar10', [127.19, 4.13])\n",
            "('shakeshakeresnet26_2x32d_cifar10', [428.89, 3.17])\n"
          ]
        }
      ],
      "source": [
        "model_names=sorted(model_names)\n",
        "for m in model_names:\n",
        "    print(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('densenet100_k12_cifar10', [1353.55, 3.66]), ('densenet40_k36_bc_cifar10', [654.6, 4.04]), ('diapreresnet164bn_cifar10', [343.37, 3.56]), ('diaresnet110_cifar10', [264.71, 4.1]), ('diaresnet164bn_cifar10', [343.6, 3.5]), ('preresnet110_cifar10', [255.68, 3.86]), ('preresnet164bn_cifar10', [255.08, 3.64]), ('preresnet272bn_cifar10', [420.38, 3.25]), ('preresnet542bn_cifar10', [833.64, 3.14]), ('pyramidnet110_a48_cifar10', [408.37, 3.72]), ('pyramidnet110_a84_cifar10', [778.15, 2.98]), ('resnet110_cifar10', [255.7, 3.69]), ('resnet164bn_cifar10', [255.31, 3.68]), ('resnet272bn_cifar10', [420.61, 3.33]), ('resnet542bn_cifar10', [833.87, 3.43]), ('resnext29_32x4d_cifar10', [780.55, 3.15]), ('rir_cifar10', [1281.08, 3.28]), ('ror3_164_cifar10', [370.72, 3.93]), ('sepreresnet164bn_cifar10', [256.32, 3.73]), ('sepreresnet272bn_cifar10', [422.45, 3.39]), ('sepreresnet542bn_cifar10', [837.78, 3.08]), ('seresnet110_cifar10', [255.98, 3.63]), ('seresnet164bn_cifar10', [256.55, 3.39]), ('seresnet272bn_cifar10', [422.68, 3.39]), ('seresnet542bn_cifar10', [838.01, 3.47]), ('seresnet56_cifar10', [127.19, 4.13]), ('shakeshakeresnet26_2x32d_cifar10', [428.89, 3.17])]\n"
          ]
        }
      ],
      "source": [
        "print(model_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oprXiQEGlTB1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/tonic/CCW/ml/hw10/mifgsm\n",
            "airplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n",
            "/home/tonic/CCW/ml/hw10\n"
          ]
        }
      ],
      "source": [
        "%cd mifgsm\n",
        "! ls\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx-X40vrD3S7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/tonic/CCW/ml/hw10/mifgsm\n",
            "airplane/\n",
            "airplane/airplane19.png\n",
            "airplane/airplane11.png\n",
            "airplane/airplane17.png\n",
            "airplane/airplane2.png\n",
            "airplane/airplane13.png\n",
            "airplane/airplane4.png\n",
            "airplane/airplane3.png\n",
            "airplane/airplane20.png\n",
            "airplane/airplane5.png\n",
            "airplane/airplane10.png\n",
            "airplane/airplane8.png\n",
            "airplane/airplane6.png\n",
            "airplane/airplane12.png\n",
            "airplane/airplane18.png\n",
            "airplane/airplane16.png\n",
            "airplane/airplane7.png\n",
            "airplane/airplane15.png\n",
            "airplane/airplane14.png\n",
            "airplane/airplane9.png\n",
            "airplane/airplane1.png\n",
            "automobile/\n",
            "automobile/automobile12.png\n",
            "automobile/automobile19.png\n",
            "automobile/automobile14.png\n",
            "automobile/automobile1.png\n",
            "automobile/automobile5.png\n",
            "automobile/automobile20.png\n",
            "automobile/automobile16.png\n",
            "automobile/automobile4.png\n",
            "automobile/automobile10.png\n",
            "automobile/automobile7.png\n",
            "automobile/automobile11.png\n",
            "automobile/automobile13.png\n",
            "automobile/automobile3.png\n",
            "automobile/automobile9.png\n",
            "automobile/automobile8.png\n",
            "automobile/automobile15.png\n",
            "automobile/automobile18.png\n",
            "automobile/automobile2.png\n",
            "automobile/automobile6.png\n",
            "automobile/automobile17.png\n",
            "bird/\n",
            "bird/bird10.png\n",
            "bird/bird14.png\n",
            "bird/bird16.png\n",
            "bird/bird13.png\n",
            "bird/bird11.png\n",
            "bird/bird4.png\n",
            "bird/bird12.png\n",
            "bird/bird19.png\n",
            "bird/bird3.png\n",
            "bird/bird7.png\n",
            "bird/bird15.png\n",
            "bird/bird2.png\n",
            "bird/bird1.png\n",
            "bird/bird9.png\n",
            "bird/bird5.png\n",
            "bird/bird17.png\n",
            "bird/bird8.png\n",
            "bird/bird6.png\n",
            "bird/bird18.png\n",
            "bird/bird20.png\n",
            "cat/\n",
            "cat/cat5.png\n",
            "cat/cat18.png\n",
            "cat/cat1.png\n",
            "cat/cat11.png\n",
            "cat/cat14.png\n",
            "cat/cat3.png\n",
            "cat/cat19.png\n",
            "cat/cat9.png\n",
            "cat/cat6.png\n",
            "cat/cat10.png\n",
            "cat/cat7.png\n",
            "cat/cat20.png\n",
            "cat/cat15.png\n",
            "cat/cat8.png\n",
            "cat/cat16.png\n",
            "cat/cat17.png\n",
            "cat/cat12.png\n",
            "cat/cat2.png\n",
            "cat/cat13.png\n",
            "cat/cat4.png\n",
            "deer/\n",
            "deer/deer11.png\n",
            "deer/deer13.png\n",
            "deer/deer10.png\n",
            "deer/deer4.png\n",
            "deer/deer7.png\n",
            "deer/deer17.png\n",
            "deer/deer6.png\n",
            "deer/deer2.png\n",
            "deer/deer12.png\n",
            "deer/deer20.png\n",
            "deer/deer18.png\n",
            "deer/deer1.png\n",
            "deer/deer15.png\n",
            "deer/deer8.png\n",
            "deer/deer9.png\n",
            "deer/deer14.png\n",
            "deer/deer19.png\n",
            "deer/deer5.png\n",
            "deer/deer3.png\n",
            "deer/deer16.png\n",
            "dog/\n",
            "dog/dog6.png\n",
            "dog/dog17.png\n",
            "dog/dog12.png\n",
            "dog/dog11.png\n",
            "dog/dog18.png\n",
            "dog/dog16.png\n",
            "dog/dog1.png\n",
            "dog/dog19.png\n",
            "dog/dog3.png\n",
            "dog/dog10.png\n",
            "dog/dog7.png\n",
            "dog/dog20.png\n",
            "dog/dog9.png\n",
            "dog/dog13.png\n",
            "dog/dog15.png\n",
            "dog/dog2.png\n",
            "dog/dog8.png\n",
            "dog/dog4.png\n",
            "dog/dog5.png\n",
            "dog/dog14.png\n",
            "frog/\n",
            "frog/frog7.png\n",
            "frog/frog15.png\n",
            "frog/frog13.png\n",
            "frog/frog3.png\n",
            "frog/frog20.png\n",
            "frog/frog18.png\n",
            "frog/frog9.png\n",
            "frog/frog12.png\n",
            "frog/frog19.png\n",
            "frog/frog6.png\n",
            "frog/frog14.png\n",
            "frog/frog1.png\n",
            "frog/frog17.png\n",
            "frog/frog4.png\n",
            "frog/frog11.png\n",
            "frog/frog10.png\n",
            "frog/frog2.png\n",
            "frog/frog8.png\n",
            "frog/frog5.png\n",
            "frog/frog16.png\n",
            "horse/\n",
            "horse/horse20.png\n",
            "horse/horse6.png\n",
            "horse/horse8.png\n",
            "horse/horse4.png\n",
            "horse/horse14.png\n",
            "horse/horse7.png\n",
            "horse/horse17.png\n",
            "horse/horse11.png\n",
            "horse/horse18.png\n",
            "horse/horse2.png\n",
            "horse/horse1.png\n",
            "horse/horse16.png\n",
            "horse/horse10.png\n",
            "horse/horse5.png\n",
            "horse/horse12.png\n",
            "horse/horse15.png\n",
            "horse/horse3.png\n",
            "horse/horse19.png\n",
            "horse/horse9.png\n",
            "horse/horse13.png\n",
            "ship/\n",
            "ship/ship3.png\n",
            "ship/ship2.png\n",
            "ship/ship20.png\n",
            "ship/ship5.png\n",
            "ship/ship18.png\n",
            "ship/ship4.png\n",
            "ship/ship1.png\n",
            "ship/ship15.png\n",
            "ship/ship8.png\n",
            "ship/ship12.png\n",
            "ship/ship13.png\n",
            "ship/ship16.png\n",
            "ship/ship14.png\n",
            "ship/ship17.png\n",
            "ship/ship7.png\n",
            "ship/ship9.png\n",
            "ship/ship11.png\n",
            "ship/ship6.png\n",
            "ship/ship19.png\n",
            "ship/ship10.png\n",
            "truck/\n",
            "truck/truck17.png\n",
            "truck/truck13.png\n",
            "truck/truck18.png\n",
            "truck/truck12.png\n",
            "truck/truck14.png\n",
            "truck/truck6.png\n",
            "truck/truck7.png\n",
            "truck/truck11.png\n",
            "truck/truck15.png\n",
            "truck/truck2.png\n",
            "truck/truck19.png\n",
            "truck/truck4.png\n",
            "truck/truck3.png\n",
            "truck/truck8.png\n",
            "truck/truck1.png\n",
            "truck/truck5.png\n",
            "truck/truck10.png\n",
            "truck/truck9.png\n",
            "truck/truck16.png\n",
            "truck/truck20.png\n",
            "/home/tonic/CCW/ml/hw10\n"
          ]
        }
      ],
      "source": [
        "%cd mifgsm\n",
        "!tar zcvf ../mifgsm.tgz *\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--9YWbhn_Evr"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_2876646/1662135385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ifgsm.tgz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('ifgsm.tgz')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7dq5LDvJD5rB"
      },
      "source": [
        "## Example of Ensemble Attack\n",
        "* Ensemble multiple models as your proxy model to increase the black-box transferability ([paper](https://arxiv.org/abs/1611.02770))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvEX_IM8D7Rx"
      },
      "outputs": [],
      "source": [
        "################ BOSS BASELINE ######################\n",
        "\n",
        "class ensembleNet(nn.Module):\n",
        "    def __init__(self, model_names):\n",
        "        super().__init__()\n",
        "        self.models = nn.ModuleList([ptcv_get_model(name, pretrained=True) for name in model_names])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        #################### TODO: boss baseline ###################\n",
        "        ensemble_logits=torch.zeros(10,1)\n",
        "        for i, m in enumerate(self.models):\n",
        "          ensemble_logits+=m(x)\n",
        "          \n",
        "        # TODO: sum up logits from multiple models  \n",
        "        return ensemble_logits"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "De5J9n3WD-56"
      },
      "source": [
        "* Construct your ensemble model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9as1WHEiD_cp"
      },
      "outputs": [],
      "source": [
        "model_names = [\n",
        "    'nin_cifar10',\n",
        "    'msdnet_cifar10',\n",
        "    'resnet110_cifar10',\n",
        "    'preresnet56_cifar10',\n",
        "    'resnext29_16x64d_cifar10',\n",
        "]\n",
        "\n",
        "for model_name in model_names:\n",
        "  model_checker(model_name)\n",
        "\n",
        "ensemble_model = ensembleNet(model_names).to(device)\n",
        "ensemble_model.eval()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4N6Me0GQECfZ"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxNrXHKsEDGx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "plt.figure(figsize=(10, 20))\n",
        "cnt = 0\n",
        "for i, cls_name in enumerate(classes):\n",
        "    path = f'{cls_name}/{cls_name}1.png'\n",
        "    # benign image\n",
        "    cnt += 1\n",
        "    plt.subplot(len(classes), 4, cnt)\n",
        "    im = Image.open(f'./data/{path}')\n",
        "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "    predict = logit.argmax(-1).item()\n",
        "    prob = logit.softmax(-1)[predict].item()\n",
        "    plt.title(f'benign: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.array(im))\n",
        "    # adversarial image\n",
        "    cnt += 1\n",
        "    plt.subplot(len(classes), 4, cnt)\n",
        "    im = Image.open(f'./fgsm/{path}')\n",
        "    logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "    predict = logit.argmax(-1).item()\n",
        "    prob = logit.softmax(-1)[predict].item()\n",
        "    plt.title(f'adversarial: {cls_name}1.png\\n{classes[predict]}: {prob:.2%}')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.array(im))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WDc6QllJEHiC"
      },
      "source": [
        "## Report Question\n",
        "* Make sure you follow below setup: the source model is \"resnet110_cifar10\", applying the vanilla fgsm attack on `dog2.png`. You can find the perturbed image in `fgsm/dog2.png`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XhFVWA6JEH8Z"
      },
      "outputs": [],
      "source": [
        "# original image\n",
        "path = f'dog/dog2.png'\n",
        "im = Image.open(f'./data/{path}')\n",
        "logit = model(transform(im).unsqueeze(0).to(device))[0]\n",
        "predict = logit.argmax(-1).item()\n",
        "prob = logit.softmax(-1)[predict].item()\n",
        "plt.title(f'benign: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
        "plt.axis('off')\n",
        "plt.imshow(np.array(im))\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# adversarial image \n",
        "adv_im = Image.open(f'./fgsm/{path}')\n",
        "logit = model(transform(adv_im).unsqueeze(0).to(device))[0]\n",
        "predict = logit.argmax(-1).item()\n",
        "prob = logit.softmax(-1)[predict].item()\n",
        "plt.title(f'adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
        "plt.axis('off')\n",
        "plt.imshow(np.array(adv_im))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NfwhnywXEMwZ"
      },
      "source": [
        "## Passive Defense - JPEG compression\n",
        "JPEG compression by imgaug package, compression rate set to 70\n",
        "\n",
        "Reference: https://imgaug.readthedocs.io/en/latest/source/api_augmenters_arithmetic.html#imgaug.augmenters.arithmetic.JpegCompression\n",
        "\n",
        "Note: If you haven't implemented the JPEG compression, this module will return an error. Don't worry about this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2T7-L-BEKYg"
      },
      "outputs": [],
      "source": [
        "import imgaug.augmenters as iaa\n",
        "\n",
        "# pre-process image\n",
        "x = transforms.ToTensor()(adv_im)*255\n",
        "x = x.permute(1, 2, 0).numpy()\n",
        "x = x.astype(np.uint8)\n",
        "\n",
        "# TODO: use \"imgaug\" package to perform JPEG compression (compression rate = 70)\n",
        "# compressed_x =  ... x .. \n",
        "\n",
        "logit = model(transform(compressed_x).unsqueeze(0).to(device))[0]\n",
        "predict = logit.argmax(-1).item()\n",
        "prob = logit.softmax(-1)[predict].item()\n",
        "plt.title(f'JPEG adversarial: dog2.png\\n{classes[predict]}: {prob:.2%}')\n",
        "plt.axis('off')\n",
        "\n",
        "\n",
        "plt.imshow(compressed_x)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
